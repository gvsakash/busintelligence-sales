## Business Intelligence for Sales Prediction 


* Preprocessing:  Dimensionality reduction using PCA, Data Extraction and classification using SVM architecture.
* Implemented machine learning models in domain of business intelligence to explore customer purchase and behavior patterns in 1,40,000 records across thirteen attributes. 
* Tested with SVM and random forest classifiers after dimensionality reduction and visualized the predictions / outputs for sales patterns. Tested with Python and documented results for feature engineering. 
* Explored with Weka as well to observe best results for NNGE and M5P tree classifiers.
* Research Paper currently under review.. More code snippets used will be added after publication.

---

**Footnotes**
>    * The main linear technique for dimensionality reduction, PCA performs a linear mapping of the data to a lower-dimensional
space in such a way that the variance of the data in the low-dimensional representation is maximized. 
>    * In practice, the covariance (and sometimes the correlation) matrix of the data is constructed and the eigenvectors 
on this matrix are computed. The eigenvectors that correspond to the largest eigenvalues (the principal components) 
can now be used to reconstruct a large fraction of the variance of the original data. 
>    * Moreover, the first few eigenvectors can often be interpreted in terms of the large-scale physical behavior of 
the system. The original space (with dimension of the number of points) has been reduced (with data loss, but 
hopefully retaining the most important variance) to the space spanned by a few eigenvectors.
